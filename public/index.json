
[{"content":"","date":"31 May 2024","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"31 May 2024","externalUrl":null,"permalink":"/tags/aws/","section":"Tags","summary":"","title":"AWS","type":"tags"},{"content":"","date":"31 May 2024","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"31 May 2024","externalUrl":null,"permalink":"/categories/guides/","section":"Categories","summary":"","title":"Guides","type":"categories"},{"content":" What is a State File? # Terraform stores information about your infrastructure in a state file. This state file keeps track of resources created by your configuration and maps them to real-world resources.\nWhen you run terraform apply or terraform destroy against your initialized configuration, Terraform writes metadata about your configuration to the state file and updates your infrastructure resources accordingly.\nState File Project # In this project, we will create an AWS instance and security group, examine the project\u0026rsquo;s state file, and use Terraform to remove infrastructure from the project\u0026rsquo;s state.\nPrerequisites # Terraform CLI 1.7+ An AWS Account AWS CLI AWS credentials configured locally with your access keys and a default region. Create Infrastructure State # Clone the Learn Terraform State Management repository\n$ git clone git clone https://github.com/hashicorp/learn-terraform-state.git Change into the new directory:\n$ cd learn-terraform-state Review the main.tf file. This configuration deploys an Ubuntu EC2 instance publicly accessible on port 8080.\nprovider \u0026#34;aws\u0026#34; { region = var.aws_region } data \u0026#34;aws_ami\u0026#34; \u0026#34;ubuntu\u0026#34; { most_recent = true filter { name = \u0026#34;name\u0026#34; values = [\u0026#34;ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\u0026#34;] } filter { name = \u0026#34;virtualization-type\u0026#34; values = [\u0026#34;hvm\u0026#34;] } owners = [\u0026#34;099720109477\u0026#34;] # Canonical } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;sg_8080\u0026#34; { name = \u0026#34;terraform-learn-state-sg-8080\u0026#34; ingress { from_port = \u0026#34;8080\u0026#34; to_port = \u0026#34;8080\u0026#34; protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } // connectivity to ubuntu mirrors is required to run `apt-get update` and `apt-get install apache2` egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = data.aws_ami.ubuntu.id instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.sg_8080.id] user_data = \u0026lt;\u0026lt;-EOF #!/bin/bash apt-get update apt-get install -y apache2 sed -i -e \u0026#39;s/80/8080/\u0026#39; /etc/apache2/ports.conf echo \u0026#34;Hello World\u0026#34; \u0026gt; /var/www/html/index.html systemctl restart apache2 EOF tags = { Name = \u0026#34;terraform-learn-state-ec2\u0026#34; } } This configuration uses the AWS provider to create an EC2 instance and a security group that allows public access.\nInitialize the directory.\n$ terraform init Initializing the backend... Initializing provider plugins... - Reusing previous version of hashicorp/aws from the dependency lock file - Installing hashicorp/aws v5.31.0... - Installed hashicorp/aws v5.31.0 (signed by HashiCorp) Terraform has been successfully initialized! You may now begin working with Terraform. Try running \u0026#34;terraform plan\u0026#34; to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. After Terraform initializes, apply the configuration and approve the run by typing yes at the prompt.\n$ terraform apply data.aws_ami.ubuntu: Reading... data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386] Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_instance.example will be created + resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ##... Plan: 2 to add, 0 to change, 0 to destroy. Changes to Outputs: + aws_region = \u0026#34;us-east-1\u0026#34; + instance_id = (known after apply) + public_ip = (known after apply) + security_group = (known after apply) Do you want to perform these actions? Terraform will perform the actions described above. Only \u0026#39;yes\u0026#39; will be accepted to approve. Enter a value: yes aws_security_group.sg_8080: Creating... aws_security_group.sg_8080: Creation complete after 3s [id=sg-0adfd0a0ade3eebdc] aws_instance.example: Creating... aws_instance.example: Still creating... [10s elapsed] aws_instance.example: Still creating... [20s elapsed] aws_instance.example: Still creating... [30s elapsed] aws_instance.example: Creation complete after 32s [id=i-05a8893f05c6a37be] Apply complete! Resources: 2 added, 0 changed, 0 destroyed. Outputs: aws_region = \u0026#34;us-east-1\u0026#34; instance_id = \u0026#34;i-05a8893f05c6a37be\u0026#34; public_ip = \u0026#34;18.212.104.187\u0026#34; security_group = \u0026#34;sg-0adfd0a0ade3eebdc\u0026#34; Examine the state file # Now that you have applied this configuration, you have a local state file that tracks the resources Terraform created. Check your directory to confirm the terraform.tfstate file exists.\n$ ls -1 LICENSE README.md main.tf new_state outputs.tf terraform.tf terraform.tfstate variables.tf You should not manually change information in your state file in a real-world situation to avoid unnecessary drift between your Terraform configuration, state, and infrastructure. Any change in state could result in your infrastructure being destroyed and recreated at your next terraform apply.\nOpen the terraform.tfstate file in your file editor.\nThis example contains few resources, so your actual state file is relatively small.\nThis file is the JSON encoded state that Terraform writes and reads at each operation. The first stanza contains information about your Terraform application.\nExplore resources in state # The resources section of the state file contains the schema for any resources you create in Terraform. Review the resources section of this file.\n\u0026#34;resources\u0026#34;: [ { \u0026#34;mode\u0026#34;: \u0026#34;data\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;aws_ami\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;ubuntu\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;provider[\\\u0026#34;registry.terraform.io/hashicorp/aws\\\u0026#34;]\u0026#34;, \u0026#34;instances\u0026#34;: [ { \u0026#34;schema_version\u0026#34;: 0, \u0026#34;attributes\u0026#34;: { \u0026#34;architecture\u0026#34;: \u0026#34;x86_64\u0026#34;, \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:ec2:us-east-1::image/ami-027a754129abb5386\u0026#34;, ##... }, ##... ] The first key in this schema is the mode. Mode refers to the type of resource Terraform creates — either a resource (managed) or a data source (data). The type key refers to the resource type - in this case, the aws_ami type is a resource available in the aws provider.\n##FIXME\n##... { \u0026#34;mode\u0026#34;: \u0026#34;managed\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;aws_instance\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;example\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;provider[\\\u0026#34;registry.terraform.io/hashicorp/aws\\\u0026#34;]\u0026#34;, \u0026#34;instances\u0026#34;: [ { \u0026#34;schema_version\u0026#34;: 1, \u0026#34;attributes\u0026#34;: { \u0026#34;ami\u0026#34;: \u0026#34;ami-027a754129abb5386\u0026#34;, \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:ec2:us-east-1:949008909725:instance/i-05a8893f05c6a37be\u0026#34;, \u0026#34;associate_public_ip_address\u0026#34;: true, \u0026#34;availability_zone\u0026#34;: \u0026#34;us-east-1a\u0026#34;, ##... \u0026#34;public_ip\u0026#34;: \u0026#34;18.212.104.187\u0026#34;, ##... \u0026#34;secondary_private_ips\u0026#34;: [], \u0026#34;security_groups\u0026#34;: [ \u0026#34;terraform-learn-state-sg-8080\u0026#34; ], \u0026#34;source_dest_check\u0026#34;: true, \u0026#34;spot_instance_request_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;subnet_id\u0026#34;: \u0026#34;subnet-0e75b9376618c682a\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;terraform-learn-state-ec2\u0026#34; }, ##... } } ] }, The aws_instance type is a managed resource with the AMI from the data.aws_ami source.\nThe instances section in this resource contains the attributes of the resource. The security_groups attribute, for example, is captured in plain text in state as opposed to the variable interpolated string in the configuration file.\nTerraform also marks dependencies between resources in state with the built-in dependency tree logic.\n##... \u0026#34;dependencies\u0026#34;: [ \u0026#34;aws_security_group.sg_8080\u0026#34;, \u0026#34;data.aws_ami.ubuntu\u0026#34; ] ##... Because your state file has a record of your dependencies, enforced by you with a depends_on attribute or by Terraform automatically, any changes to the dependencies will force a change to the dependent resource.\n","date":"31 May 2024","externalUrl":null,"permalink":"/posts/learning-terraform/terraform-state/","section":"Posts \u0026 Projects","summary":"What is a State File?","title":"How to Manage Resources in Terraform State","type":"posts"},{"content":"","date":"31 May 2024","externalUrl":null,"permalink":"/tags/iac/","section":"Tags","summary":"","title":"IAC","type":"tags"},{"content":" Welcome! # In this page, I\u0026rsquo;ve added guides for projects I\u0026rsquo;ve worked on for learning tech.\n","date":"31 May 2024","externalUrl":null,"permalink":"/posts/","section":"Posts \u0026 Projects","summary":"Welcome!","title":"Posts \u0026 Projects","type":"posts"},{"content":"","date":"31 May 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"31 May 2024","externalUrl":null,"permalink":"/tags/terraform/","section":"Tags","summary":"","title":"Terraform","type":"tags"},{"content":"","date":"31 May 2024","externalUrl":null,"permalink":"/posts/learning-terraform/","section":"Posts \u0026 Projects","summary":"","title":"Terraform Learning Projects","type":"posts"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/azure/","section":"Tags","summary":"","title":"Azure","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/cisco/","section":"Tags","summary":"","title":"Cisco","type":"tags"},{"content":" Save AWS Access Keys for Terraform Admin Account # Create an AWS credentials file so that Terraform can get the programmatic credentials for the AWS administrator pushing configs via Terraform. % mkdir ~/.aws/credentials\nNavigate to https://console.aws.amazon.com\nNavigate to IAM and search for Access Keys. Click on Manage Access Keys for admin user\nNavigate to the Access keys menu to generate the aws_access_key_id and aws_secret_access_key. Copy these keys.\nGo back to terminal and edit the ~/.aws/credentials file to paste the keys here:\n[default] aws_access_key_id = \u0026lt;access_key_id_here\u0026gt; aws_secret_access_key = \u0026lt;secret_access_key_here\u0026gt; Save the file. Use Terraform to Create an S3 bucket # Create a directory for the project. I created one called Configure_S3_Bucket_Terraform\nAdd a file called main.tf\n% mkdir S3_Configure_Bucket_Terraform % touch main.tf Paste the following code into main.tf and replace \u0026lt;your-name\u0026gt; with your name after the bucket argument provider \u0026#34;aws\u0026#34; { region = \u0026#34;us-east-2\u0026#34; } resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;first_bucket\u0026#34; { bucket = \u0026#34;\u0026lt;your-name\u0026gt;-first-bucket\u0026#34; } Initialize Terraform from your directory: % terraform init\nOutput:\n(venv) host% Configure_S3_Bucket_Terraform % terraform init Initializing the backend... Initializing provider plugins... - Finding latest version of hashicorp/aws... - Installing hashicorp/aws v5.49.0... - Installed hashicorp/aws v5.49.0 (signed by HashiCorp) Terraform has created a lock file .terraform.lock.hcl to record the provider selections it made above. Include this file in your version control repository so that Terraform can guarantee to make the same selections by default when you run \u0026#34;terraform init\u0026#34; in the future. Terraform has been successfully initialized! You may now begin working with Terraform. Try running \u0026#34;terraform plan\u0026#34; to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Apply your Terraform configuration: % terraform apply\nType yes and hit enter (venv) host % Configure_S3_Bucket_Terraform % terraform apply Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_s3_bucket.first_bucket will be created + resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;first_bucket\u0026#34; { + acceleration_status = (known after apply) + acl = (known after apply) + arn = (known after apply) + bucket = \u0026#34;mikes-first-bucket\u0026#34; + bucket_domain_name = (known after apply) + bucket_prefix = (known after apply) + bucket_regional_domain_name = (known after apply) + force_destroy = false + hosted_zone_id = (known after apply) + id = (known after apply) + object_lock_enabled = (known after apply) + policy = (known after apply) + region = (known after apply) + request_payer = (known after apply) + tags_all = (known after apply) + website_domain = (known after apply) + website_endpoint = (known after apply) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only \u0026#39;yes\u0026#39; will be accepted to approve. Enter a value: yes aws_s3_bucket.first_bucket: Creating... aws_s3_bucket.first_bucket: Creation complete after 2s [id=vus-first-bucket] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Verify Bucket Creation # Navigate to the Buckets menu of your AWS console.\nVerify that your Bucket was configured:\nTerraform Destroy # Run the % terraform destroy command\naws_s3_bucket.first_bucket: Refreshing state... [id=vus-first-bucket] Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: # aws_s3_bucket.first_bucket will be destroyed - resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;first_bucket\u0026#34; { - arn = \u0026#34;arn:aws:s3:::vus-first-bucket\u0026#34; -\u0026gt; null - bucket = \u0026#34;vus-first-bucket\u0026#34; -\u0026gt; null - bucket_domain_name = \u0026#34;vus-first-bucket.s3.amazonaws.com\u0026#34; -\u0026gt; null - bucket_regional_domain_name = \u0026#34;vus-first-bucket.s3.us-east-2.amazonaws.com\u0026#34; -\u0026gt; null - force_destroy = false -\u0026gt; null - hosted_zone_id = \u0026#34;Z2O1EMRO9K5GLX\u0026#34; -\u0026gt; null - id = \u0026#34;vus-first-bucket\u0026#34; -\u0026gt; null - object_lock_enabled = false -\u0026gt; null - region = \u0026#34;us-east-2\u0026#34; -\u0026gt; null - request_payer = \u0026#34;BucketOwner\u0026#34; -\u0026gt; null - tags = {} -\u0026gt; null - tags_all = {} -\u0026gt; null # (3 unchanged attributes hidden) - grant { - id = \u0026#34;32d5a6ff5e649dc794f25ddc46a8ef24c48bc2f7f85318544f20829b0721b334\u0026#34; -\u0026gt; null - permissions = [ - \u0026#34;FULL_CONTROL\u0026#34;, ] -\u0026gt; null - type = \u0026#34;CanonicalUser\u0026#34; -\u0026gt; null # (1 unchanged attribute hidden) } - server_side_encryption_configuration { - rule { - bucket_key_enabled = false -\u0026gt; null - apply_server_side_encryption_by_default { - sse_algorithm = \u0026#34;AES256\u0026#34; -\u0026gt; null # (1 unchanged attribute hidden) } } } - versioning { - enabled = false -\u0026gt; null - mfa_delete = false -\u0026gt; null } } Plan: 0 to add, 0 to change, 1 to destroy. Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure, as shown above. There is no undo. Only \u0026#39;yes\u0026#39; will be accepted to confirm. Enter a value: yes aws_s3_bucket.first_bucket: Destroying... [id=vus-first-bucket] aws_s3_bucket.first_bucket: Destruction complete after 0s Destroy complete! Resources: 1 destroyed. ","date":"29 May 2024","externalUrl":null,"permalink":"/posts/learning-terraform/configure_s3_bucket_terraform/","section":"Posts \u0026 Projects","summary":"Save AWS Access Keys for Terraform Admin Account # Create an AWS credentials file so that Terraform can get the programmatic credentials for the AWS administrator pushing configs via Terraform.","title":"How to Create an S3 Bucket in AWS Using Terraform","type":"posts"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/json/","section":"Tags","summary":"","title":"JSON","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/meraki/","section":"Tags","summary":"","title":"Meraki","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/network-administration/","section":"Tags","summary":"","title":"Network Administration","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/posts/networking-projects/","section":"Posts \u0026 Projects","summary":"","title":"Network Automation and Configuration Projects","type":"posts"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/networking/","section":"Tags","summary":"","title":"Networking","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/saml/","section":"Tags","summary":"","title":"SAML","type":"tags"},{"content":"This tutorial will guide you through the process of using Python to download the Layer 3 and Layer 7 rules from a Meraki MX into a CSV spreadsheet.\nWhat you Need # Access to the Meraki Dashboard\nA Meraki MX Appliance\nMeraki API Key\nBEFORE PROCEEDING, GENERATE YOUR API KEY AND SAVE IT SOMEWHERE SECURE\nGitHub Repo # You can either download the files from my Github\nor clone the repo:\ngit clone https://github.com/mikeovu/Meraki_Firewall_Rules_to_CSV.git Python Script # Here is the Python code that takes the firewall rules from the Meraki Dashboard and converts it into JSON \u0026ndash;\u0026gt; CSV.\nDo NOT run the code yet. Review it and then proceed to the Installation/Configuration section below\nIn the repo, it\u0026rsquo;s named security_to_csv.py:\nimport meraki import json import config import csv dashboard = meraki.DashboardAPI(config.api_key,single_request_timeout=999999) # Uses the Meraki library to grab Organization info. orgs = dashboard.organizations.getOrganizations() # Displays the org name and ID for org in orgs: print(\u0026#34;Organization name: \u0026#34; + str(org[\u0026#34;name\u0026#34;]) + \u0026#34; | \u0026#34; + \u0026#34;ID: \u0026#34; + str(org[\u0026#34;id\u0026#34;])) # Prompts user to select Organization ID org_id = input(\u0026#34;Select an organization id: \u0026#34;) # Displays dashboard orrganization mapped to organization ID networks = dashboard.organizations.getOrganizationNetworks(organizationId=org_id) # Displays all networks in the organization the user has selected for network in networks: print(\u0026#34;Network name: \u0026#34; + str(network[\u0026#34;name\u0026#34;]) + \u0026#34; | \u0026#34; + \u0026#34;ID: \u0026#34; + str(network[\u0026#34;id\u0026#34;])) print(\u0026#34;-------------------------------------\u0026#34;) breaker = \u0026#34;1\u0026#34; networks_to_output = [] # Promps user to specify network ids that they would like to see while breaker == \u0026#34;1\u0026#34;: net_id = input(\u0026#34;Continue to add network IDs that you want to receive L3 and L7 firewall rule outputs, enter 0 when finished\\n\u0026#34;) if net_id == \u0026#34;0\u0026#34;: breaker = \u0026#34;0\u0026#34; break networks_to_output.append(net_id) confirmation = input(\u0026#34;press y to proceed \u0026#34;) # Iterates through L7 rules of chosen network and creates a json file containing l7 policies for network in networks_to_output: with open(\u0026#39;firewall_rules/l7_rules.json\u0026#39;, \u0026#39;w\u0026#39;) as f: output_l7_response = dashboard.appliance.getNetworkApplianceFirewallL7FirewallRules(networkId=network) json.dump(output_l7_response, f, indent=2) # Iterates through L3 rules of chosen network and creates a json file containing L3 policies for network in networks_to_output: with open(\u0026#39;firewall_rules/l3_rules.json\u0026#39;, \u0026#39;w\u0026#39;) as f: output_l3_response = dashboard.appliance.getNetworkApplianceFirewallL3FirewallRules(networkId=network) json.dump(output_l3_response, f, indent=2) # Convert L7_rules.json to csv with open(\u0026#39;firewall_rules/l7_rules.json\u0026#39;) as l7_rules: l7_policies = json.load(l7_rules) policies = l7_policies[\u0026#39;rules\u0026#39;] # Open csv for writing l7 rules rule_data = open(\u0026#39;firewall_rules/l7_rules.csv\u0026#39;, \u0026#39;w\u0026#39;) # create the csv writer object csv_writer = csv.writer(rule_data) # Counter variable used for writing # headers to the csv file count = 0 for rule in policies: if count == 0: # Writing headers of CSV file header = rule.keys() csv_writer.writerow(header) count += 1 # Writing data of CSV file csv_writer.writerow(rule.values()) l7_rules.close() # Convert L3_rules.json to csv with open(\u0026#39;firewall_rules/l3_rules.json\u0026#39;) as l3_rules: l3_policies = json.load(l3_rules) policies = l3_policies[\u0026#39;rules\u0026#39;] # Open csv for writing l7 rules rule_data = open(\u0026#39;firewall_rules/l3_rules.csv\u0026#39;, \u0026#39;w\u0026#39;) # create the csv writer object csv_writer = csv.writer(rule_data) # Counter variable used for writing # headers to the csv file count = 0 for rule in policies: if count == 0: # Writing headers of CSV file header = rule.keys() csv_writer.writerow(header) count += 1 # Writing data of CSV file csv_writer.writerow(rule.values()) l3_rules.close() MX firewall rules you will be outputting to JSON and CSV # Here are the firewall rules specified in the Layer 3 and Layer 7 sections of the Security \u0026amp; SD-WAN \u0026gt; Configure \u0026gt; Firewall menu in the dashboard.\nInstallation/Configuration # Open the config.py file from the repository and paste in your Meraki API Key. api_key=\u0026#34;\u0026#34; install the dependencies required for the python script ~$ pip install -r requirements.txt run the python script ~$ python3 security_to_csv.py You will be asked to specify the Dashboard Organization you will be requesting firewall rules from. You will be asked to specify the network you will be requesting firewall rules from. Firewall Rules Directory # L3 Firewall Rules CSV \u0026amp; JSON # L7 Firewall Rules CSV \u0026amp; JSON # ","date":"29 May 2024","externalUrl":null,"permalink":"/posts/networking-projects/outputting_firewall_rules_to_dashboard/","section":"Posts \u0026 Projects","summary":"This tutorial will guide you through the process of using Python to download the Layer 3 and Layer 7 rules from a Meraki MX into a CSV spreadsheet.","title":"Using Python to Convert Meraki MX Firewall Rules into JSON and CSV Files","type":"posts"},{"content":" Configuration steps on AzureAD and Meraki Dashboards # This guide seems redundant, but there are some quirks that are not accounted for in the official Meraki documentation. I\u0026rsquo;ve included details to help avoid confusion during the configuration process\nFollow the steps in Meraki\u0026rsquo;s AnyConnect Azure AD SAML Configuration document. and stop at Step 7.\nBefore you start Step 7, navigate to your Meraki Dashboard and navigate to the Security \u0026amp; SD-WAN \u0026gt; Configure\u0026gt; Client VPN page.\nClick on AnyConnect Settings and select Enabled.\nCopy your hostname to your clipboard under the Client Connection Details page:\nNavigate back to Step 7 of the AnyConnect Azure AD SAML Configuration document. and follow the formatting instructions, using your hostname. mx-security-mmgjjktzjp.dynamic-m.com/saml/sp/metadata/SAML mx-security-mmgjjktzjp.dynamic-m.com/saml/sp/acs When you get to Step 9 of the document, make sure you add the hostname with https:// in front of it in the AnyConnect Server URL field: Navigate back to the AzureAD portal and click on the Single Sign-on menu.\nCheck the Basic SAML Configuration box to ensure you’ve entered the correct hostname in the Identifier (Entity ID) and Reply URL (Assertion Consumer Service URL) fields:\nGive AzureAD at least 30 minutes to accept the configuration. When I tested this, authentication kept failing within the first 30 minutes. After 30 minutes, I was able to authenticate without changing any settings. Test Client VPN on your End Device # If you did not set up an AnyConnect Profile for your end devices yet, follow the subsequent steps:\nOpen the AnyConnect Secure Mobility Client on your machine:\nCopy and paste the AnyConnect Server URL into the VPN field.\nWhen you press Connect, a Microsoft popup window will appear and prompt you to login using your credentials. ","date":"19 April 2023","externalUrl":null,"permalink":"/posts/networking-projects/configuring_anyconnect_azuread_saml/","section":"Posts \u0026 Projects","summary":"Configuration steps on AzureAD and Meraki Dashboards # This guide seems redundant, but there are some quirks that are not accounted for in the official Meraki documentation.","title":"How to Configure AzureAD SAML Authentication for AnyConnect VPN on Meraki","type":"posts"},{"content":"","date":"19 April 2023","externalUrl":null,"permalink":"/tags/vpn/","section":"Tags","summary":"","title":"VPN","type":"tags"},{"content":" Professional History # I have been an IT professional, specializing in network administration and design for a decade. Here\u0026rsquo;s an abridged story of how I went from a political science major in college to where I am now:\n🏫 2005 - 2009: Majored in Political Science at UCLA and worked as an AV Technician for the student Union.\n🎵 2006 - 2010: Toured around the country as a drummer in a band, where I obtained certain skills that would come in handy later in life. Some of the skills included building a social network in the music industry, face to face sales at malls (soliciting our album), and audio visual engineering (live sound and recording).\n💻 2011 - 2013: Learned the true value of a degree in political science 💩 This meant that I had to leverage my experience as a former college AV tech, as well as the skills I gained as a touring musician to obtain a job in corporate AV support. During my time as a corpoate AV support tech, I learned how to become an IT systems administrator, configuring and troubleshooting media servers, network switches, and end user machines. I eventually landed a job as a contractor at Google, which was a big milestone for me as an IT professional.\n📶 2014 - Present: I got a job at Coursea, where I was able to dive into network administration. This is where I decided to stick with network engineering as a long-term career path. I became a CCNA, worked in network operations for a few more years at a couple more companies - Cisco Meraki, Roche, and Stitch Fix. This experience lead to my current position as a pre-sales Solutions Engineer at Cisco Meraki\nSkills and Technology # Cisco Technologies - Where I gained knowledge and experience Routing, Switching, Wireless, Security, IoT Linux Administration - general systems administration for distributions like debian and ubuntu, and shell scripting\nWindows Administration - general Windows systems administration, powershell, and Active Directory Python - Language I use for network automation scripts.\nPostman - Tool I use for testing API endpoints.\nVisual Studio Code - My IDE of choice.\nGit - What I use to version control my projects. For example, managing the repo for this Hugo site.\nGithub - Where I store all of my project repositories.\nTerraform - The automation tool I like to use to deploy infrastructure.\nAWS - One of the cloud providers I have experience with.\nAzure - The other cloud provider I have experience with.\nCertifications # Logo Name Date Cisco Certified Network Associate (CCNA) Expires 2027 Cisco Certified DevNet Associate Expires 2027 Personal Life # My family and I love going on outdoor adventures. Not including the newest addition to the family for safety reasons.\nI\u0026rsquo;m an avid mountain biker and I love traveling with the purpose of exploring new trails.\nI\u0026rsquo;ve been a drummer for a couple of decades and used to be in a touring band.\n","date":"1 January 0001","externalUrl":null,"permalink":"/about/","section":"","summary":"Professional History # I have been an IT professional, specializing in network administration and design for a decade.","title":"About Me","type":"page"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]