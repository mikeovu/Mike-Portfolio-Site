
[{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/aws/","section":"Tags","summary":"","title":"AWS","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/cisco/","section":"Tags","summary":"","title":"Cisco","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/categories/guides/","section":"Categories","summary":"","title":"Guides","type":"categories"},{"content":" Save AWS Access Keys for Terraform Admin Account # Create an AWS credentials file so that Terraform can get the programmatic credentials for the AWS administrator pushing configs via Terraform. % mkdir ~/.aws/credentials\nNavigate to https://console.aws.amazon.com\nNavigate to IAM and search for Access Keys. Click on Manage Access Keys for admin user\nNavigate to the Access keys menu to generate the aws_access_key_id and aws_secret_access_key. Copy these keys.\nGo back to terminal and edit the ~/.aws/credentials file to paste the keys here:\n[default] aws_access_key_id = \u0026lt;access_key_id_here\u0026gt; aws_secret_access_key = \u0026lt;secret_access_key_here\u0026gt; Save the file. Use Terraform to Create an S3 bucket # Create a directory for the project. I created one called Configure_S3_Bucket_Terraform\nAdd a file called main.tf\n% mkdir S3_Configure_Bucket_Terraform % touch main.tf Paste the following code into main.tf and replace \u0026lt;your-name\u0026gt; with your name after the bucket argument provider \u0026#34;aws\u0026#34; { region = \u0026#34;us-east-2\u0026#34; } resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;first_bucket\u0026#34; { bucket = \u0026#34;\u0026lt;your-name\u0026gt;-first-bucket\u0026#34; } Initialize Terraform from your directory: % terraform init\nOutput:\n(venv) host% Configure_S3_Bucket_Terraform % terraform init Initializing the backend... Initializing provider plugins... - Finding latest version of hashicorp/aws... - Installing hashicorp/aws v5.49.0... - Installed hashicorp/aws v5.49.0 (signed by HashiCorp) Terraform has created a lock file .terraform.lock.hcl to record the provider selections it made above. Include this file in your version control repository so that Terraform can guarantee to make the same selections by default when you run \u0026#34;terraform init\u0026#34; in the future. Terraform has been successfully initialized! You may now begin working with Terraform. Try running \u0026#34;terraform plan\u0026#34; to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Apply your Terraform configuration: % terraform apply\nType yes and hit enter (venv) host % Configure_S3_Bucket_Terraform % terraform apply Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_s3_bucket.first_bucket will be created + resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;first_bucket\u0026#34; { + acceleration_status = (known after apply) + acl = (known after apply) + arn = (known after apply) + bucket = \u0026#34;mikes-first-bucket\u0026#34; + bucket_domain_name = (known after apply) + bucket_prefix = (known after apply) + bucket_regional_domain_name = (known after apply) + force_destroy = false + hosted_zone_id = (known after apply) + id = (known after apply) + object_lock_enabled = (known after apply) + policy = (known after apply) + region = (known after apply) + request_payer = (known after apply) + tags_all = (known after apply) + website_domain = (known after apply) + website_endpoint = (known after apply) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only \u0026#39;yes\u0026#39; will be accepted to approve. Enter a value: yes aws_s3_bucket.first_bucket: Creating... aws_s3_bucket.first_bucket: Creation complete after 2s [id=vus-first-bucket] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Verify Bucket Creation # Navigate to the Buckets menu of your AWS console.\nVerify that your Bucket was configured:\nTerraform Destroy # Run the % terraform destroy command\naws_s3_bucket.first_bucket: Refreshing state... [id=vus-first-bucket] Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: # aws_s3_bucket.first_bucket will be destroyed - resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;first_bucket\u0026#34; { - arn = \u0026#34;arn:aws:s3:::vus-first-bucket\u0026#34; -\u0026gt; null - bucket = \u0026#34;vus-first-bucket\u0026#34; -\u0026gt; null - bucket_domain_name = \u0026#34;vus-first-bucket.s3.amazonaws.com\u0026#34; -\u0026gt; null - bucket_regional_domain_name = \u0026#34;vus-first-bucket.s3.us-east-2.amazonaws.com\u0026#34; -\u0026gt; null - force_destroy = false -\u0026gt; null - hosted_zone_id = \u0026#34;Z2O1EMRO9K5GLX\u0026#34; -\u0026gt; null - id = \u0026#34;vus-first-bucket\u0026#34; -\u0026gt; null - object_lock_enabled = false -\u0026gt; null - region = \u0026#34;us-east-2\u0026#34; -\u0026gt; null - request_payer = \u0026#34;BucketOwner\u0026#34; -\u0026gt; null - tags = {} -\u0026gt; null - tags_all = {} -\u0026gt; null # (3 unchanged attributes hidden) - grant { - id = \u0026#34;32d5a6ff5e649dc794f25ddc46a8ef24c48bc2f7f85318544f20829b0721b334\u0026#34; -\u0026gt; null - permissions = [ - \u0026#34;FULL_CONTROL\u0026#34;, ] -\u0026gt; null - type = \u0026#34;CanonicalUser\u0026#34; -\u0026gt; null # (1 unchanged attribute hidden) } - server_side_encryption_configuration { - rule { - bucket_key_enabled = false -\u0026gt; null - apply_server_side_encryption_by_default { - sse_algorithm = \u0026#34;AES256\u0026#34; -\u0026gt; null # (1 unchanged attribute hidden) } } } - versioning { - enabled = false -\u0026gt; null - mfa_delete = false -\u0026gt; null } } Plan: 0 to add, 0 to change, 1 to destroy. Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure, as shown above. There is no undo. Only \u0026#39;yes\u0026#39; will be accepted to confirm. Enter a value: yes aws_s3_bucket.first_bucket: Destroying... [id=vus-first-bucket] aws_s3_bucket.first_bucket: Destruction complete after 0s Destroy complete! Resources: 1 destroyed. ","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/posts/configure_s3_bucket_terraform/","section":"Informational Posts","summary":"Save AWS Access Keys for Terraform Admin Account # Create an AWS credentials file so that Terraform can get the programmatic credentials for the AWS administrator pushing configs via Terraform.","title":"How to Create an S3 Bucket in AWS Using Terraform","type":"posts"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/iac/","section":"Tags","summary":"","title":"IAC","type":"tags"},{"content":"Welcome to the posts page!\nHere, you\u0026rsquo;ll find informational guides that I\u0026rsquo;ve developed through my technical learning journey.\n","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/posts/","section":"Informational Posts","summary":"Welcome to the posts page!","title":"Informational Posts","type":"posts"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/json/","section":"Tags","summary":"","title":"JSON","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/meraki/","section":"Tags","summary":"","title":"Meraki","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/networking/","section":"Tags","summary":"","title":"Networking","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/terraform/","section":"Tags","summary":"","title":"Terraform","type":"tags"},{"content":"This tutorial will guide you through the process of using Python to download the Layer 3 and Layer 7 rules from a Meraki MX into a CSV spreadsheet.\nWhat you Need # Access to the Meraki Dashboard\nA Meraki MX Appliance\nMeraki API Key\nBEFORE PROCEEDING, GENERATE YOUR API KEY AND SAVE IT SOMEWHERE SECURE\nGitHub Repo # You can either download the files from my Github\nor clone the repo:\ngit clone https://github.com/mikeovu/Meraki_Firewall_Rules_to_CSV.git Python Script # Here is the Python code that takes the firewall rules from the Meraki Dashboard and converts it into JSON \u0026ndash;\u0026gt; CSV.\nDo NOT run the code yet. Review it and then proceed to the Installation/Configuration section below\nIn the repo, it\u0026rsquo;s named security_to_csv.py:\nimport meraki import json import config import csv dashboard = meraki.DashboardAPI(config.api_key,single_request_timeout=999999) # Uses the Meraki library to grab Organization info. orgs = dashboard.organizations.getOrganizations() # Displays the org name and ID for org in orgs: print(\u0026#34;Organization name: \u0026#34; + str(org[\u0026#34;name\u0026#34;]) + \u0026#34; | \u0026#34; + \u0026#34;ID: \u0026#34; + str(org[\u0026#34;id\u0026#34;])) # Prompts user to select Organization ID org_id = input(\u0026#34;Select an organization id: \u0026#34;) # Displays dashboard orrganization mapped to organization ID networks = dashboard.organizations.getOrganizationNetworks(organizationId=org_id) # Displays all networks in the organization the user has selected for network in networks: print(\u0026#34;Network name: \u0026#34; + str(network[\u0026#34;name\u0026#34;]) + \u0026#34; | \u0026#34; + \u0026#34;ID: \u0026#34; + str(network[\u0026#34;id\u0026#34;])) print(\u0026#34;-------------------------------------\u0026#34;) breaker = \u0026#34;1\u0026#34; networks_to_output = [] # Promps user to specify network ids that they would like to see while breaker == \u0026#34;1\u0026#34;: net_id = input(\u0026#34;Continue to add network IDs that you want to receive L3 and L7 firewall rule outputs, enter 0 when finished\\n\u0026#34;) if net_id == \u0026#34;0\u0026#34;: breaker = \u0026#34;0\u0026#34; break networks_to_output.append(net_id) confirmation = input(\u0026#34;press y to proceed \u0026#34;) # Iterates through L7 rules of chosen network and creates a json file containing l7 policies for network in networks_to_output: with open(\u0026#39;firewall_rules/l7_rules.json\u0026#39;, \u0026#39;w\u0026#39;) as f: output_l7_response = dashboard.appliance.getNetworkApplianceFirewallL7FirewallRules(networkId=network) json.dump(output_l7_response, f, indent=2) # Iterates through L3 rules of chosen network and creates a json file containing L3 policies for network in networks_to_output: with open(\u0026#39;firewall_rules/l3_rules.json\u0026#39;, \u0026#39;w\u0026#39;) as f: output_l3_response = dashboard.appliance.getNetworkApplianceFirewallL3FirewallRules(networkId=network) json.dump(output_l3_response, f, indent=2) # Convert L7_rules.json to csv with open(\u0026#39;firewall_rules/l7_rules.json\u0026#39;) as l7_rules: l7_policies = json.load(l7_rules) policies = l7_policies[\u0026#39;rules\u0026#39;] # Open csv for writing l7 rules rule_data = open(\u0026#39;firewall_rules/l7_rules.csv\u0026#39;, \u0026#39;w\u0026#39;) # create the csv writer object csv_writer = csv.writer(rule_data) # Counter variable used for writing # headers to the csv file count = 0 for rule in policies: if count == 0: # Writing headers of CSV file header = rule.keys() csv_writer.writerow(header) count += 1 # Writing data of CSV file csv_writer.writerow(rule.values()) l7_rules.close() # Convert L3_rules.json to csv with open(\u0026#39;firewall_rules/l3_rules.json\u0026#39;) as l3_rules: l3_policies = json.load(l3_rules) policies = l3_policies[\u0026#39;rules\u0026#39;] # Open csv for writing l7 rules rule_data = open(\u0026#39;firewall_rules/l3_rules.csv\u0026#39;, \u0026#39;w\u0026#39;) # create the csv writer object csv_writer = csv.writer(rule_data) # Counter variable used for writing # headers to the csv file count = 0 for rule in policies: if count == 0: # Writing headers of CSV file header = rule.keys() csv_writer.writerow(header) count += 1 # Writing data of CSV file csv_writer.writerow(rule.values()) l3_rules.close() MX firewall rules you will be outputting to JSON and CSV # Here are the firewall rules specified in the Layer 3 and Layer 7 sections of the Security \u0026amp; SD-WAN \u0026gt; Configure \u0026gt; Firewall menu in the dashboard.\nInstallation/Configuration # Open the config.py file from the repository and paste in your Meraki API Key. api_key=\u0026#34;\u0026#34; install the dependencies required for the python script ~$ pip install -r requirements.txt run the python script ~$ python3 security_to_csv.py You will be asked to specify the Dashboard Organization you will be requesting firewall rules from. You will be asked to specify the network you will be requesting firewall rules from. Firewall Rules Directory # L3 Firewall Rules CSV \u0026amp; JSON # L7 Firewall Rules CSV \u0026amp; JSON # ","date":"29 May 2024","externalUrl":null,"permalink":"/Mike-Portfolio-Site/posts/outputting_firewall_rules_to_dashboard/","section":"Informational Posts","summary":"This tutorial will guide you through the process of using Python to download the Layer 3 and Layer 7 rules from a Meraki MX into a CSV spreadsheet.","title":"Using Python to Convert Meraki MX Firewall Rules into JSON and CSV Files","type":"posts"},{"content":"","date":"19 April 2023","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/azure/","section":"Tags","summary":"","title":"Azure","type":"tags"},{"content":" Configuration steps on AzureAD and Meraki Dashboards # This guide seems redundant, but there are some quirks that are not accounted for in the official Meraki documentation. I\u0026rsquo;ve included details to help avoid confusion during the configuration process\nFollow the steps in Meraki\u0026rsquo;s AnyConnect Azure AD SAML Configuration document. and stop at Step 7.\nBefore you start Step 7, navigate to your Meraki Dashboard and navigate to the Security \u0026amp; SD-WAN \u0026gt; Configure\u0026gt; Client VPN page.\nClick on AnyConnect Settings and select Enabled.\nCopy your hostname to your clipboard under the Client Connection Details page:\nNavigate back to Step 7 of the AnyConnect Azure AD SAML Configuration document. and follow the formatting instructions, using your hostname. mx-security-mmgjjktzjp.dynamic-m.com/saml/sp/metadata/SAML mx-security-mmgjjktzjp.dynamic-m.com/saml/sp/acs When you get to Step 9 of the document, make sure you add the hostname with https:// in front of it in the AnyConnect Server URL field: Navigate back to the AzureAD portal and click on the Single Sign-on menu.\nCheck the Basic SAML Configuration box to ensure you‚Äôve entered the correct hostname in the Identifier (Entity ID) and Reply URL (Assertion Consumer Service URL) fields:\nGive AzureAD at least 30 minutes to accept the configuration. When I tested this, authentication kept failing within the first 30 minutes. After 30 minutes, I was able to authenticate without changing any settings. Test Client VPN on your End Device # If you did not set up an AnyConnect Profile for your end devices yet, follow the subsequent steps:\nOpen the AnyConnect Secure Mobility Client on your machine:\nCopy and paste the AnyConnect Server URL into the VPN field.\nWhen you press Connect, a Microsoft popup window will appear and prompt you to login using your credentials. ","date":"19 April 2023","externalUrl":null,"permalink":"/Mike-Portfolio-Site/posts/configuring_anyconnect_azuread_saml/","section":"Informational Posts","summary":"Configuration steps on AzureAD and Meraki Dashboards # This guide seems redundant, but there are some quirks that are not accounted for in the official Meraki documentation.","title":"How to Configure AzureAD SAML Authentication for AnyConnect VPN on Meraki","type":"posts"},{"content":"","date":"19 April 2023","externalUrl":null,"permalink":"/Mike-Portfolio-Site/tags/vpn/","section":"Tags","summary":"","title":"VPN","type":"tags"},{"content":" Professional History # I have been an IT professional, specializing in network administration and design for a decade. However, pursuing a career in IT and Network engineering was not my original plan. Here\u0026rsquo;s an abridged version of my journey from political science major to solutions engineer:\nüè´ 2005 - 2009: Majored in Political Science at UCLA and worked as an AV Technician for the student Union.\nüéµ 2006 - 2010: Toured around the country as a drummer in a band and learned the hard way that\nüíª 2011 - 2013: Learned the true value of a degree in political science and used my experience as an AV technician to find a job as a corporate AV technician at companies like AMD and Google. I used every opportunity to learn and gain experience in everything IT - windows/linux administration, virtualization, cloud computing, networking.\nüì∂ 2014 - Present: I got a job at Coursea, where I was able to dive into network administration. This is where I decided to stick with network engineering as a long-term career path. I became a CCNA, worked in network operations for a few more years at a couple more companies - Cisco Meraki, Roche, and Stitch Fix. This experience lead to my current position as a pre-sales Solutions Engineer at Cisco Meraki\nSkills and Technology # Cisco Technologies - Where I gained knowledge and experience Routing, Switching, Wireless, Security, IoT Linux Administration - general systems administration for distributions like debian and ubuntu, and shell scripting\nWindows Administration - general Windows systems administration, powershell, and Active Directory Python - Language I use for network automation scripts.\nPostman - Tool I use for testing API endpoints.\nVisual Studio Code - My IDE of choice.\nGit - What I use to version control my projects. For example, managing the repo for this Hugo site.\nGithub - Where I store all of my project repositories.\nTerraform - The automation tool I like to use to deploy infrastructure.\nAWS - One of the cloud providers I have experience with.\nAzure - The other cloud provider I have experience with.\nCertifications # Logo Name Date Cisco Certified Network Associate (CCNA) Expires 2027 Cisco Certified DevNet Associate Expires 2027 Personal Life # My family and I love going on outdoor adventures. Not including the newest addition to the family for safety reasons.\nI\u0026rsquo;m an avid mountain biker and I love traveling with the purpose of exploring new trails.\nI\u0026rsquo;ve been a drummer for a couple of decades and used to be in a touring band.\n","date":"1 January 0001","externalUrl":null,"permalink":"/Mike-Portfolio-Site/about/","section":"","summary":"Professional History # I have been an IT professional, specializing in network administration and design for a decade.","title":"About Me","type":"page"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/Mike-Portfolio-Site/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/Mike-Portfolio-Site/series/","section":"Series","summary":"","title":"Series","type":"series"}]